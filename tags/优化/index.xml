<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>优化 on</title><link>https://jieye-ericx.github.io/tags/%E4%BC%98%E5%8C%96/</link><description>Recent content in 优化 on</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://jieye-ericx.github.io/tags/%E4%BC%98%E5%8C%96/index.xml" rel="self" type="application/rss+xml"/><item><title>Mysql join优化</title><link>https://jieye-ericx.github.io/Mysql-join%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://jieye-ericx.github.io/Mysql-join%E4%BC%98%E5%8C%96/</guid><description>先说结论 首先，使用[[小表]]作为驱动表
如果可以使用 Index Nested-Loop Join 算法，也就是说可以用上被驱动表上的索引，其实是没问题的； 如果使用 Block Nested-Loop Join 算法，扫描行数就会过多。尤其是在大表上的 join 操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种 join 尽量不要用。 判断要不要使用 join 语句时，就是看 explain 结果里面，Extra 字段里面有没有出现“Block Nested Loop”字样</description></item><item><title>Redis 解决mysql查询速度慢</title><link>https://jieye-ericx.github.io/Redis-%E8%A7%A3%E5%86%B3mysql%E6%9F%A5%E8%AF%A2%E9%80%9F%E5%BA%A6%E6%85%A2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://jieye-ericx.github.io/Redis-%E8%A7%A3%E5%86%B3mysql%E6%9F%A5%E8%AF%A2%E9%80%9F%E5%BA%A6%E6%85%A2/</guid><description>有一个应用需要上传一组 ID 到服务器来查询这些 ID 所对应的数据，数据库中存储的数据量是7千万，每次上传的 ID 数量一般都是几百至上千数量级别。
以前的解决方案
数据存储在Oracle中，为ID建立了索引； 查询时，先将这些上传的ID数据存储到临时表中，然后用表关联的方法来查询。 这样做的优点是减少了查询次数（不用每个ID都查询一次），减少了解析SQL的时间（只需要执行1次查询SQL，但是多了插入数据的SQL处理时间）。
但是这样的设计仍然存在巨大的提升空间，当并发查询的数量增加时，数据库的响应就会很久。虽然建立了索引，但是每个ID查询的时间复杂度仍是O(logn)级别的，那么总的查询时间复杂度就应该是m*O(logn)。不知道Oracle对表关联查询有做了哪些优化，但应该也是改变不了时间复杂度的级别。
解决方法
一遇到读数据库存在瓶颈的问题，首先想到的就是要用内存数据库，用缓存来解决。首选 Redis，因为Redis是一种提供了丰富数据结构的key-value数据库，value可以存储STRING（字符串）、HASH（哈希），LIST（列表），ZSET（有序集）。
首先需要将数据的存储改成 key-value 架构。简单的做法就是一个ID对应一个字符串的 Value。但是一个 ID 可以对应多条数据，而且一条数据内又可以包含多个字段。这时候就需要将这些数据重新组合一下，拼在一起，或者是采用列表、哈希或集合来存储 Value。</description></item><item><title>使用LinkedBlockingQueue时线程池的坑</title><link>https://jieye-ericx.github.io/%E4%BD%BF%E7%94%A8LinkedBlockingQueue%E6%97%B6%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E5%9D%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://jieye-ericx.github.io/%E4%BD%BF%E7%94%A8LinkedBlockingQueue%E6%97%B6%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E5%9D%91/</guid><description>最近遇到一个问题HTTP 线程快速上升，外部服务调用超时，服务本身响应时间超长
现象 应用平常运行正常没有任何问题，突然有一天应用的访问量爆增，出现外部服务调用超时，服务本身响应时间超长，HTTP线程快速上升，但CPU利用率并不高
定位思路 分析这类线程异常问题，最直接有效的方法是查看线程的 dump
根据dump极有可能是线程池设置不合理导致，查看线程池 cachedTreadPool 的定义，发现定义如下：
核心线程数为 cpu 的数量2倍，最大线程数为 cpu 的数量乘以配置的数量，任务队列为 LinkedBlockingQueue，也就是最大数量为 Integer.MAX_VALUE，对线程池了解的话，这样的设置会导致线程池的任务堆积。因为线程池默认实现是核心线程数满了之后，再填充任务队列，如果线程数量小于最大线程数再创建线程。而这儿设置的任务队列几乎是无界的，也就是说这个线程池真正工作的线程只会是 cpu 的数量的 2 倍。</description></item><item><title>系统监控异常处理</title><link>https://jieye-ericx.github.io/%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://jieye-ericx.github.io/%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</guid><description>写起来思路很清晰，但实际上整个过程花费了大半天的时间，其实排查的过程中，有很多关键点没有抓到，有很多现象，是可以凭经验条件反射的推断出原因的：
看到cpu使用率上涨，用jstack看使用cpu的线程，以及该线程在跑什么代码。 找到是gc线程，然后看gc曲线是否正常。 看堆内存曲线，正常的曲线是锯齿形的，如果不是，一次full GC之后内存没有明显下降，那基本可以推断发生内存泄漏了。 怀疑是内存泄漏的问题，可以跑jmap，然后拉到MAT分析。 第四步比较耗时的话，可以同时跑这个命令：jmap -histo pid。看看有没有线索。 jvm的一些工具：jstack、jmap、jstat、jhat。包括可视化工具：MAT、jvisualvm</description></item></channel></rss>